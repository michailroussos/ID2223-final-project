{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f139ba67",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for SOLANA bitcoin</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è The tasks of this script\n",
    "1. Download historical prices for SOLANA as a CSV file\n",
    "2. Update the path of the CSV file in this notebook to point to the one that you downloaded\n",
    "5. Create an account on www.hopsworks.ai and get your HOPSWORKS_API_KEY\n",
    "6. Run notebook to upload the feature on a hopsworks feature storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f447120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb50142-06be-4003-9fd0-6b19c095b010",
   "metadata": {},
   "source": [
    "### IF YOU WANT TO WIPE OUT ALL OF YOUR FEATURES AND MODELS, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014f3362-87f5-4abd-bb57-bebd28638bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "# with open('../../data/hopsworks-api-key.txt', 'r') as file:\n",
    "#     os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "# #proj = hopsworks.login()\n",
    "#util.purge_project(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156f96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b8d1a-62a5-4a1d-b805-6e83cafcd29f",
   "metadata": {},
   "source": [
    "## Hopsworks API Key\n",
    "You need to have registered an account on app.hopsworks.ai.\n",
    "You will be prompted to enter your API key here, unless you set it as the environment variable HOPSWORKS_API_KEY (my preffered approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 14:44:38,029 INFO: Initializing external client\n",
      "2024-12-12 14:44:38,030 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2024-12-12 14:44:40,242 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1164448\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HOPSWORKS_API_KEY\"] = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "    \n",
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa1e9a",
   "metadata": {},
   "source": [
    "### Add historical data to hopsworks feature storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6a996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>233.173548</td>\n",
       "      <td>232.943871</td>\n",
       "      <td>240.952903</td>\n",
       "      <td>224.819677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.866262</td>\n",
       "      <td>13.037690</td>\n",
       "      <td>12.429703</td>\n",
       "      <td>13.874963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>209.500000</td>\n",
       "      <td>209.600000</td>\n",
       "      <td>220.170000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>226.575000</td>\n",
       "      <td>224.005000</td>\n",
       "      <td>235.310000</td>\n",
       "      <td>212.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>236.200000</td>\n",
       "      <td>235.870000</td>\n",
       "      <td>241.910000</td>\n",
       "      <td>227.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>237.970000</td>\n",
       "      <td>238.030000</td>\n",
       "      <td>246.805000</td>\n",
       "      <td>233.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256.570000</td>\n",
       "      <td>256.900000</td>\n",
       "      <td>264.200000</td>\n",
       "      <td>252.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price        open        high         low\n",
       "count   31.000000   31.000000   31.000000   31.000000\n",
       "mean   233.173548  232.943871  240.952903  224.819677\n",
       "std     12.866262   13.037690   12.429703   13.874963\n",
       "min    209.500000  209.600000  220.170000  201.000000\n",
       "25%    226.575000  224.005000  235.310000  212.895000\n",
       "50%    236.200000  235.870000  241.910000  227.670000\n",
       "75%    237.970000  238.030000  246.805000  233.895000\n",
       "max    256.570000  256.900000  264.200000  252.750000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_data = pd.read_csv(\"data/SOL_USD Binance Historical Data.csv\")\n",
    "hist_data.columns = hist_data.columns.str.lower()\n",
    "hist_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87366092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'price', 'open', 'high', 'low', 'vol.', 'change %'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() \n",
    "solana_fg = fs.get_or_create_feature_group(\n",
    "    name='solana',\n",
    "    description='Solana price',\n",
    "    version=2,\n",
    "    primary_key=[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da09d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beea7594",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1164448/featurestores/1155151/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270040,\"usrMsg\":\", the provided feature name vol. is invalid. Feature names can only contain lower case characters, numbers and underscores, have to start with a letter and cannot be longer than 63 characters or empty.\",\"errorMsg\":\"Illegal feature name\"}', error code: 270040, error msg: Illegal feature name, user msg: , the provided feature name vol. is invalid. Feature names can only contain lower case characters, numbers and underscores, have to start with a letter and cannot be longer than 63 characters or empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msolana_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhist_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hsfs/feature_group.py:2940\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, wait)\u001b[0m\n\u001b[1;32m   2937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offline_backfill_every_hr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2938\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline_backfill_every_hr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offline_backfill_every_hr\n\u001b[0;32m-> 2940\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2941\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2944\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mget_type()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m   2951\u001b[0m     \u001b[38;5;66;03m# Also, only compute statistics if stream is False.\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m     \u001b[38;5;66;03m# if True, the backfill job has not been triggered and the data has not been inserted (it's in Kafka)\u001b[39;00m\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_statistics()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hsfs/core/feature_group_engine.py:171\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m    165\u001b[0m util\u001b[38;5;241m.\u001b[39mvalidate_embedding_feature_type(\n\u001b[1;32m    166\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39membedding_index, dataframe_features\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39m_id:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# only save metadata if feature group does not exist\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_feature_group_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_options\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m    177\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hsfs/core/feature_group_engine.py:482\u001b[0m, in \u001b[0;36mFeatureGroupEngine.save_feature_group_metadata\u001b[0;34m(self, feature_group, dataframe_features, write_options)\u001b[0m\n\u001b[1;32m    469\u001b[0m     _write_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    470\u001b[0m         [\n\u001b[1;32m    471\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: v}\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     )\n\u001b[1;32m    478\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39m_deltastreamer_jobconf \u001b[38;5;241m=\u001b[39m DeltaStreamerJobConf(\n\u001b[1;32m    479\u001b[0m         _write_options, _spark_options\n\u001b[1;32m    480\u001b[0m     )\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Group created successfully, explore it at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;241m+\u001b[39m util\u001b[38;5;241m.\u001b[39mget_feature_group_url(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hsfs/core/feature_group_api.py:60\u001b[0m, in \u001b[0;36mFeatureGroupApi.save\u001b[0;34m(self, feature_group_instance)\u001b[0m\n\u001b[1;32m     55\u001b[0m query_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpectationsuite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformationfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     57\u001b[0m }\n\u001b[1;32m     58\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     59\u001b[0m feature_group_object \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mupdate_from_response_json(\n\u001b[0;32m---> 60\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_group_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hopsworks_common/decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/crypto-env/lib/python3.10/site-packages/hopsworks_common/client/base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[1;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1164448/featurestores/1155151/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270040,\"usrMsg\":\", the provided feature name vol. is invalid. Feature names can only contain lower case characters, numbers and underscores, have to start with a letter and cannot be longer than 63 characters or empty.\",\"errorMsg\":\"Illegal feature name\"}', error code: 270040, error msg: Illegal feature name, user msg: , the provided feature name vol. is invalid. Feature names can only contain lower case characters, numbers and underscores, have to start with a letter and cannot be longer than 63 characters or empty."
     ]
    }
   ],
   "source": [
    "solana_fg.insert(hist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe74862",
   "metadata": {},
   "source": [
    "### Request solana price from last available data till now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db566a2d",
   "metadata": {},
   "source": [
    "### Getting missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5cea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Response', 'Message', 'HasWarning', 'Type', 'RateLimit', 'Data'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://min-api.cryptocompare.com/data/v2/histoday\"\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "crypto_api_key = os.getenv(\"CRYPTO_API_KEY\")\n",
    "\n",
    "\n",
    "# Set the parameters for the API request\n",
    "params = {\n",
    "    \"fsym\": \"SOL\",  # From symbol (e.g., Bitcoin)\n",
    "    \"tsym\": \"USD\",  # To symbol (e.g., US Dollar)\n",
    "    \"limit\": 30,    # Number of days of data to retrieve\n",
    "    \"toTs\": None,   # Timestamp for the end of the period (None for latest data)\n",
    "    \"api_key\": crypto_api_key\n",
    "}\n",
    "\n",
    "response = trigger_request(url, params)\n",
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb7e06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aggregated': False,\n",
       " 'TimeFrom': 1731369600,\n",
       " 'TimeTo': 1733961600,\n",
       " 'Data': [{'time': 1731369600,\n",
       "   'high': 225.3,\n",
       "   'low': 205.03,\n",
       "   'open': 222.42,\n",
       "   'volumefrom': 3207955.53,\n",
       "   'volumeto': 687618053.08,\n",
       "   'close': 211.86,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731456000,\n",
       "   'high': 220.78,\n",
       "   'low': 201.12,\n",
       "   'open': 211.86,\n",
       "   'volumefrom': 3280352.4,\n",
       "   'volumeto': 695358114.93,\n",
       "   'close': 215.45,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731542400,\n",
       "   'high': 222.79,\n",
       "   'low': 206.84,\n",
       "   'open': 215.45,\n",
       "   'volumefrom': 2390257.3,\n",
       "   'volumeto': 514053398.69,\n",
       "   'close': 209.54,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731628800,\n",
       "   'high': 220.4,\n",
       "   'low': 204.62,\n",
       "   'open': 209.54,\n",
       "   'volumefrom': 2089124.27,\n",
       "   'volumeto': 443402898.19,\n",
       "   'close': 218.51,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731715200,\n",
       "   'high': 221.99,\n",
       "   'low': 213.61,\n",
       "   'open': 218.51,\n",
       "   'volumefrom': 1522225.59,\n",
       "   'volumeto': 331681217.77,\n",
       "   'close': 215.77,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731801600,\n",
       "   'high': 241.96,\n",
       "   'low': 212.27,\n",
       "   'open': 215.77,\n",
       "   'volumefrom': 2733055.7,\n",
       "   'volumeto': 635702351.09,\n",
       "   'close': 237.54,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731888000,\n",
       "   'high': 248.41,\n",
       "   'low': 234.11,\n",
       "   'open': 237.54,\n",
       "   'volumefrom': 2824027.47,\n",
       "   'volumeto': 680971149.83,\n",
       "   'close': 239.94,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1731974400,\n",
       "   'high': 247.71,\n",
       "   'low': 233.8,\n",
       "   'open': 239.94,\n",
       "   'volumefrom': 1916539.68,\n",
       "   'volumeto': 462771223.05,\n",
       "   'close': 237.96,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732060800,\n",
       "   'high': 242.67,\n",
       "   'low': 230.78,\n",
       "   'open': 237.96,\n",
       "   'volumefrom': 1809309.07,\n",
       "   'volumeto': 426617836.59,\n",
       "   'close': 235.65,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732147200,\n",
       "   'high': 259.81,\n",
       "   'low': 230.04,\n",
       "   'open': 235.65,\n",
       "   'volumefrom': 3197520.06,\n",
       "   'volumeto': 793245850.05,\n",
       "   'close': 256.72,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732233600,\n",
       "   'high': 264.52,\n",
       "   'low': 251.84,\n",
       "   'open': 256.72,\n",
       "   'volumefrom': 1930270.43,\n",
       "   'volumeto': 497034963.4,\n",
       "   'close': 257.21,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732320000,\n",
       "   'high': 264.16,\n",
       "   'low': 253.09,\n",
       "   'open': 257.21,\n",
       "   'volumefrom': 1540433.13,\n",
       "   'volumeto': 397600303.58,\n",
       "   'close': 255.15,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732406400,\n",
       "   'high': 259.95,\n",
       "   'low': 241.28,\n",
       "   'open': 255.15,\n",
       "   'volumefrom': 1318863.47,\n",
       "   'volumeto': 331064481.64,\n",
       "   'close': 252.98,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732492800,\n",
       "   'high': 256.69,\n",
       "   'low': 231.2,\n",
       "   'open': 252.98,\n",
       "   'volumefrom': 2246138.62,\n",
       "   'volumeto': 547356000.23,\n",
       "   'close': 234.15,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732579200,\n",
       "   'high': 239.86,\n",
       "   'low': 221.86,\n",
       "   'open': 234.15,\n",
       "   'volumefrom': 2017476.18,\n",
       "   'volumeto': 465157248.79,\n",
       "   'close': 230.62,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732665600,\n",
       "   'high': 243.56,\n",
       "   'low': 227.57,\n",
       "   'open': 230.62,\n",
       "   'volumefrom': 1535640.84,\n",
       "   'volumeto': 364043739.43,\n",
       "   'close': 242.26,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732752000,\n",
       "   'high': 245.48,\n",
       "   'low': 232.94,\n",
       "   'open': 242.26,\n",
       "   'volumefrom': 877224.57,\n",
       "   'volumeto': 208985240.69,\n",
       "   'close': 237.63,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732838400,\n",
       "   'high': 246.89,\n",
       "   'low': 236.66,\n",
       "   'open': 237.63,\n",
       "   'volumefrom': 1307891.16,\n",
       "   'volumeto': 316868423.69,\n",
       "   'close': 243.46,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1732924800,\n",
       "   'high': 245.4,\n",
       "   'low': 237.64,\n",
       "   'open': 243.46,\n",
       "   'volumefrom': 856576.11,\n",
       "   'volumeto': 206542138.89,\n",
       "   'close': 237.75,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733011200,\n",
       "   'high': 239.95,\n",
       "   'low': 234.32,\n",
       "   'open': 237.75,\n",
       "   'volumefrom': 1042536.95,\n",
       "   'volumeto': 247065369.07,\n",
       "   'close': 236.96,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733097600,\n",
       "   'high': 238.36,\n",
       "   'low': 220.17,\n",
       "   'open': 236.96,\n",
       "   'volumefrom': 2782727.81,\n",
       "   'volumeto': 631780477.65,\n",
       "   'close': 225.81,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733184000,\n",
       "   'high': 239.79,\n",
       "   'low': 215.15,\n",
       "   'open': 225.81,\n",
       "   'volumefrom': 2498009.97,\n",
       "   'volumeto': 569372675.86,\n",
       "   'close': 234.11,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733270400,\n",
       "   'high': 240.95,\n",
       "   'low': 224.79,\n",
       "   'open': 234.11,\n",
       "   'volumefrom': 2424018.49,\n",
       "   'volumeto': 564765211.47,\n",
       "   'close': 229.48,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733356800,\n",
       "   'high': 244.95,\n",
       "   'low': 223.26,\n",
       "   'open': 229.48,\n",
       "   'volumefrom': 3120708.13,\n",
       "   'volumeto': 736104487.64,\n",
       "   'close': 236.17,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733443200,\n",
       "   'high': 247.06,\n",
       "   'low': 231.17,\n",
       "   'open': 236.17,\n",
       "   'volumefrom': 1779255.05,\n",
       "   'volumeto': 425038287.56,\n",
       "   'close': 237.18,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733529600,\n",
       "   'high': 243.7,\n",
       "   'low': 234.41,\n",
       "   'open': 237.18,\n",
       "   'volumefrom': 1155071.17,\n",
       "   'volumeto': 276310183.73,\n",
       "   'close': 238.34,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733616000,\n",
       "   'high': 241.65,\n",
       "   'low': 233.36,\n",
       "   'open': 238.34,\n",
       "   'volumefrom': 723712.35,\n",
       "   'volumeto': 171567432.86,\n",
       "   'close': 237.2,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733702400,\n",
       "   'high': 237.42,\n",
       "   'low': 205.36,\n",
       "   'open': 237.2,\n",
       "   'volumefrom': 2284778.33,\n",
       "   'volumeto': 509504278.85,\n",
       "   'close': 216.81,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733788800,\n",
       "   'high': 221.02,\n",
       "   'low': 203.3,\n",
       "   'open': 216.81,\n",
       "   'volumefrom': 2836727.29,\n",
       "   'volumeto': 602479362.87,\n",
       "   'close': 213.75,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733875200,\n",
       "   'high': 230.82,\n",
       "   'low': 211.64,\n",
       "   'open': 213.75,\n",
       "   'volumefrom': 1782926.44,\n",
       "   'volumeto': 399771792,\n",
       "   'close': 227.42,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''},\n",
       "  {'time': 1733961600,\n",
       "   'high': 233.53,\n",
       "   'low': 225.86,\n",
       "   'open': 227.42,\n",
       "   'volumefrom': 619014.56,\n",
       "   'volumeto': 142407765.33,\n",
       "   'close': 230.21,\n",
       "   'conversionType': 'direct',\n",
       "   'conversionSymbol': ''}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"Data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 5: Read your CSV file into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical air quality data as a CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc3a1212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/aristotelous-air-quality.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipinitialspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/final_project_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/final_project_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/final_project_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/final_project_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/final_project_env/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/aristotelous-air-quality.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file,  parse_dates=['date'], skipinitialspace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812eb37-04e3-4291-8d77-a69ef7a195bc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 6: Data cleaning</span>\n",
    "\n",
    "\n",
    "### Rename columns if needed and drop unneccessary columns\n",
    "\n",
    "We want to have a DataFrame with 2 columns - `date` and `pm25` after this cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcfa73",
   "metadata": {},
   "source": [
    "## Check the data types for the columns in your DataFrame\n",
    "\n",
    " * `date` should be of type   datetime64[ns] \n",
    " * `pm25` should be of type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>lagged_pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>374.0</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>56.0</td>\n",
       "      <td>686.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>476.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>45.0</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>70.0</td>\n",
       "      <td>108.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   pm25  lagged_pm25\n",
       "0    2019-11-07  374.0   999.000000\n",
       "1    2019-11-08   56.0   686.500000\n",
       "2    2019-11-09   62.0   476.333333\n",
       "3    2019-11-10   45.0   164.000000\n",
       "4    2019-11-11   57.0    54.333333\n",
       "...         ...    ...          ...\n",
       "1762 2024-11-03   70.0   108.333333\n",
       "1763 2024-11-04   47.0    63.666667\n",
       "1764 2024-11-05   54.0    60.666667\n",
       "1765 2024-11-06   43.0    57.000000\n",
       "1766 2024-11-07   42.0    48.000000\n",
       "\n",
       "[1767 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These commands will succeed if your CSV file didn't have a `median` or `timestamp` column\n",
    "df = df.rename(columns={\"median\": \"pm25\"})\n",
    "df = df.rename(columns={\"timestamp\": \"date\"})\n",
    "\n",
    "df_aq = df[['date', 'pm25']]\n",
    "df_aq['pm25'] = df_aq['pm25'].astype('float32')\n",
    "df_aq = util.create_lagged_pm25(df_aq)\n",
    "\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1767 entries, 0 to 1766\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         1767 non-null   datetime64[ns]\n",
      " 1   pm25         1767 non-null   float32       \n",
      " 2   lagged_pm25  1767 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float32(1), float64(1)\n",
      "memory usage: 34.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19911f73",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 7: Drop any rows with missing data </span>\n",
    "It will make the model training easier if there is no missing data in the rows, so we drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>lagged_pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>374.0</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>56.0</td>\n",
       "      <td>686.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>476.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>45.0</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>70.0</td>\n",
       "      <td>108.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   pm25  lagged_pm25\n",
       "0    2019-11-07  374.0   999.000000\n",
       "1    2019-11-08   56.0   686.500000\n",
       "2    2019-11-09   62.0   476.333333\n",
       "3    2019-11-10   45.0   164.000000\n",
       "4    2019-11-11   57.0    54.333333\n",
       "...         ...    ...          ...\n",
       "1762 2024-11-03   70.0   108.333333\n",
       "1763 2024-11-04   47.0    63.666667\n",
       "1764 2024-11-05   54.0    60.666667\n",
       "1765 2024-11-06   43.0    57.000000\n",
       "1766 2024-11-07   42.0    48.000000\n",
       "\n",
       "[1767 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089c159",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 8: Add country, city, street, url to the DataFrame </span>\n",
    "\n",
    "Your CSV file may have many other air quality measurement columns. We will only work with the `pm25` column.\n",
    "\n",
    "We add the columns for the country, city, and street names that you changed for your Air Quality sensor.\n",
    "\n",
    "We also want to make sure the `pm25` column is a float32 data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>lagged_pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>374.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>56.0</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>62.0</td>\n",
       "      <td>476.333333</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>45.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>70.0</td>\n",
       "      <td>108.333333</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>greece</td>\n",
       "      <td>athens</td>\n",
       "      <td>aristotelous</td>\n",
       "      <td>https://api.waqi.info/feed/@12414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   pm25  lagged_pm25 country    city        street  \\\n",
       "0    2019-11-07  374.0   999.000000  greece  athens  aristotelous   \n",
       "1    2019-11-08   56.0   686.500000  greece  athens  aristotelous   \n",
       "2    2019-11-09   62.0   476.333333  greece  athens  aristotelous   \n",
       "3    2019-11-10   45.0   164.000000  greece  athens  aristotelous   \n",
       "4    2019-11-11   57.0    54.333333  greece  athens  aristotelous   \n",
       "...         ...    ...          ...     ...     ...           ...   \n",
       "1762 2024-11-03   70.0   108.333333  greece  athens  aristotelous   \n",
       "1763 2024-11-04   47.0    63.666667  greece  athens  aristotelous   \n",
       "1764 2024-11-05   54.0    60.666667  greece  athens  aristotelous   \n",
       "1765 2024-11-06   43.0    57.000000  greece  athens  aristotelous   \n",
       "1766 2024-11-07   42.0    48.000000  greece  athens  aristotelous   \n",
       "\n",
       "                                    url  \n",
       "0     https://api.waqi.info/feed/@12414  \n",
       "1     https://api.waqi.info/feed/@12414  \n",
       "2     https://api.waqi.info/feed/@12414  \n",
       "3     https://api.waqi.info/feed/@12414  \n",
       "4     https://api.waqi.info/feed/@12414  \n",
       "...                                 ...  \n",
       "1762  https://api.waqi.info/feed/@12414  \n",
       "1763  https://api.waqi.info/feed/@12414  \n",
       "1764  https://api.waqi.info/feed/@12414  \n",
       "1765  https://api.waqi.info/feed/@12414  \n",
       "1766  https://api.waqi.info/feed/@12414  \n",
       "\n",
       "[1767 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your sensor may have columns we won't use, so only keep the date and pm25 columns\n",
    "# If the column names in your DataFrame are different, rename your columns to `date` and `pm25`\n",
    "df_aq['country']=country\n",
    "df_aq['city']=city\n",
    "df_aq['street']=street\n",
    "df_aq['url']=aqicn_url\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8276",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 9: Download the Historical Weather Data </span>\n",
    "\n",
    "https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean,precipitation_sum,wind_speed_10m_max,wind_direction_10m_dominant\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 33.98945236206055¬∞N -83.37078857421875¬∞E\n",
      "Elevation 220.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "weather_df = util.get_historical_weather(city, earliest_aq_date, str(today), latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1837 entries, 0 to 1836\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         1837 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean          1837 non-null   float32       \n",
      " 2   precipitation_sum            1837 non-null   float32       \n",
      " 3   wind_speed_10m_max           1837 non-null   float32       \n",
      " 4   wind_direction_10m_dominant  1837 non-null   float32       \n",
      " 5   city                         1837 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 10: Define Data Validation Rules </span>\n",
    "\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"pm25\", \"min_value\": -0.1, \"max_value\": 500.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd82f7",
   "metadata": {},
   "source": [
    "#### Save country, city, street names as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSOR_LOCATION_JSON already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\n",
      "{\"country\": \"greece\", \"city\": \"athens\", \"street\": \"aristotelous\", \"aqicn_url\": \"https://api.waqi.info/feed/@12414\", \"latitude\": 33.96, \"longitude\": -83.38}\n"
     ]
    }
   ],
   "source": [
    "dict_obj = {\n",
    "    \"country\": country,\n",
    "    \"city\": city,\n",
    "    \"street\": street,\n",
    "    \"aqicn_url\": aqicn_url,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "try:\n",
    "    secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"SENSOR_LOCATION_JSON already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\")\n",
    "    existing_key = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "    print(f\"{existing_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 12: Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality_with_lagged',\n",
    "    description='Air Quality characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'street', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:42:38,590 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1164448/fs/1155151/fg/1348979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7141ac542ad49b1851a867c1cce3c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1767 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_with_lagged_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1164448/jobs/named/air_quality_with_lagged_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x16ae83310>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 672806\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 18.0,\n",
       "         \"element_count\": 1767,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T09:42:38.000590Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-18T22:42:38.590072+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"07f64bc4-a5f6-11ef-b8f9-c64ac0f33020\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241118T214238.590006Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577effca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x16a92b010>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in acqcn.org)\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "air_quality_fg.update_feature_description(\"lagged_pm25\", \"Three day average of pm25\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:42:51,618 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1164448/fs/1155151/fg/1339763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538cd5e8fbe14abf916b2ef894876f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1837 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1164448/jobs/named/weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x16ae81710>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 663568\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 1837,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T09:42:51.000618Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 663569\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 5.634890556335449,\n",
       "         \"element_count\": 1837,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-18T09:42:51.000618Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-18T22:42:51.618158+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"0fba38ca-a5f6-11ef-b8f9-c64ac0f33020\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241118T214251.618078Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x16ae42650>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc16b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Daily Feature Pipeline \n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029117",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Exercises:** \n",
    " </span> \n",
    "\n",
    "Extra Homework:\n",
    "\n",
    "  * Try adding a new feature based on a rolling window of 3 days for 'pm25'\n",
    "      * This is not easy, as forecasting more than 1 day in the future, you won't have the previous 3 days of pm25 measurements.\n",
    "      * df.set_index(\"date\").rolling(3).mean() is only the start....\n",
    "  * Parameterize the notebook, so that you can provide the `country`/`street`/`city`/`url`/`csv_file` as parameters. \n",
    "      * Hint: this will also require making the secret name (`SENSOR_LOCATION_JSON`), e.g., add the street name as part of the secret name. Then you have to pass that secret name as a parameter when running the operational feature pipeline and batch inference pipelines.\n",
    "      * After you have done this, collect the street/city/url/csv files for all the sensors in your city or region and you make dashboards for all of the air quality sensors in your city/region. You could even then add a dashboard for your city/region, as done [here for Poland](https://github.com/erno98/ID2223).\n",
    "\n",
    "Improve this AI System\n",
    "  * As of mid 2024, there is no API call available to download historical data from the AQIN website. You could improve this system by writing a PR to download the CSV file using Python Selenium and the URL for the sensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb407899",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
